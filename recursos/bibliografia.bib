% Encoding: UTF-8

@Article{transformer_based,
	
	AUTHOR={Chang, Ande  and Ji, Yuting  and Bie, Yiming },
	
	TITLE={Transformer-based short-term traffic forecasting model considering traffic spatiotemporal correlation},
	
	JOURNAL={Frontiers in Neurorobotics},
	
	VOLUME={19},
	
	YEAR={2025},
	
	URL={https://www.frontiersin.org/journals/neurorobotics/articles/10.3389/fnbot.2025.1527908},
	
	DOI={10.3389/fnbot.2025.1527908},
	
	ISSN={1662-5218},
	
}

@Online{pgcpv,
	author = {{Gobierno Vasco, Eusko Jaurlaritza}},
	title = {Tercer Plan General de Carreteras del País Vasco 2017-2028},
	url = {https://www.euskadi.eus/tercer-plan-general-de-carreteras-del-pais-vasco-2017-2028/web01-a2bideko/es/},
	year = {2020},
	urldate = {2020-05-25},
	note = {Accedido el 18 de abril de 2025},
}

@Article{forecastArimaLtsm,
	AUTHOR = {Katambire, Vienna N. and Musabe, Richard and Uwitonze, Alfred and Mukanyiligira, Didacienne},
	TITLE = {Forecasting the Traffic Flow by Using ARIMA and LSTM Models: Case of Muhima Junction},
	JOURNAL = {Forecasting},
	VOLUME = {5},
	YEAR = {2023},
	NUMBER = {4},
	PAGES = {616--628},
	URL = {https://www.mdpi.com/2571-9394/5/4/34},
	ISSN = {2571-9394},
	ABSTRACT = {Traffic operation efficiency is greatly impacted by the increase in travel demand and the increase in vehicle ownership. The continued increase in traffic demand has rendered the importance of controlling traffic, especially at intersections. In general, the inefficiency of traffic scheduling leads to traffic congestion, resulting in a rise in fuel consumption, exhaust emissions, and poor quality of service. Various methods for time series forecasting have been proposed for adaptive and remote traffic control. The prediction of traffic has attracted profound attention for improving the reliability and efficiency of traffic flow scheduling while reducing congestion. Therefore, in this work, we studied the problem of the current traffic situation at Muhima Junction one of the busiest junctions in Kigali city. Future traffic rates were forecasted by employing long short-term memory (LSTM) and autoregressive integrated moving average (ARIMA) models, respectively. Both the models’ performance criteria for adequacy were the mean absolute error (MAE), mean absolute percentage error (MAPE), and root mean squared error (RMSE). The results revealed that LSTM is the best-fitting model for monthly traffic flow prediction. Within this analysis, we proposed an adaptive traffic flow prediction that builds on the features of vehicle-to-infrastructure communication and the Internet of Things (IoT) to control traffic while enhancing the quality of service at the junctions. The real-time actuation of traffic-responsive signal control can be assured when real-time traffic-based signal actuation is reliable.},
	DOI = {10.3390/forecast5040034}
}

Sí, claro que sí. Aquí tienes la referencia BibTeX para el artículo que proporcionaste:

Fragmento de código

@Article{forecastSarima,
	author    = {Kumar, S. Vasantha and Vanajakshi, Lelitha},
	journal   = {European Transport Research Review},
	title     = {Short-term traffic flow prediction using seasonal ARIMA model with limited input data},
	year      = {2015},
	volume    = {7},
	number    = {3},
	pages     = {21},
	doi       = {10.1007/s12544-015-0170-8},
	issn      = {1866-8887},
	url       = {https://doi.org/10.1007/s12544-015-0170-8},
	abstract  = {Accurate prediction of traffic flow is an integral component in most of the Intelligent Transportation Systems (ITS) applications. The data driven approach using Box-Jenkins Autoregressive Integrated Moving Average (ARIMA) models reported in most studies demands sound database for model building. Hence, the applicability of these models remains a question in places where the data availability could be an issue. The present study tries to overcome the above issue by proposing a prediction scheme using Seasonal ARIMA (SARIMA) model for short term prediction of traffic flow using only limited input data.},
	date      = {2015-06-13},
	keywords  = {ARIMA; ITS; prediction; SARIMA; short-term traffic flow},
}

@inproceedings{forecastKalman,
	author={Momin, Khondhaker Al and Barua, Saurav and Jamil, Md. Shahreer and Hamim, Omar Faruqe},
	title={Short duration traffic flow prediction using kalman filtering},
	ISSN={0094-243X},
	url={http://dx.doi.org/10.1063/5.0129721},
	DOI={10.1063/5.0129721},
	booktitle={6TH INTERNATIONAL CONFERENCE ON CIVIL ENGINEERING FOR SUSTAINABLE DEVELOPMENT (ICCESD 2022)},
	publisher={AIP Publishing},
	year={2023} 
}

@Article{liu2020congestion,
	title={Congestion time prediction model based on multiple regression analysis and survival analysis},
	author={Liu, Yang and Liu, Zhaohui and Liu, Jing and Zhang, Xue and Tang, Meng},
	journal={PLOS ONE},
	volume={15},
	number={7},
	pages={e0235660},
	year={2020},
	publisher={Public Library of Science},
	doi={10.1371/journal.pone.0235660},
	url={https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0235660}
}

@Article{omar2024,
	title     = {One-step vs horizon-step training strategies for multi-step traffic flow forecasting with direct particle swarm optimization grid search support vector regression and long short-term memory},
	author    = {Omar, M. and Yakub, F. and Abdullah, S. S. and Abd Rahim, M. S. and Zuhairi, A. H. and Govindan, N.},
	journal   = {Expert Systems with Applications},
	volume    = {252},
	pages     = {124154},
	year      = {2024},
	doi       = {10.1016/j.eswa.2024.124154}
}

@Article{forecastRf,
	author = {Wu, Jiong},
	year = {2024},
	month = {08},
	pages = {323-331},
	title = {A Study on Short-Term Traffic Flow Prediction Based on Random Forest Regression},
	volume = {107},
	journal = {Highlights in Science, Engineering and Technology},
	doi = {10.54097/tv6vfy08},
	url = {https://www.researchgate.net/publication/383208801_A_Study_on_Short-Term_Traffic_Flow_Prediction_Based_on_Random_Forest_Regression}
}

@Article{forecastKnn,
	author = {Aditya, Fikri and Nasution, Surya and Virgono, Agus},
	year = {2020},
	month = {10},
	pages = {},
	title = {Traffic Flow Prediction using SUMO Application with K-Nearest Neighbor (KNN) Method},
	volume = {12},
	journal = {International Journal of Integrated Engineering},
	doi = {10.30880/ijie.2020.12.07.011},
	url = {https://www.researchgate.net/publication/346622922_Traffic_Flow_Prediction_using_SUMO_Application_with_K-Nearest_Neighbor_KNN_Method}
}

@Article{mccullochPitts1943,
	title={A logical calculus of the ideas immanent in nervous activity},
	author={McCulloch, Warren S. and Pitts, Walter},
	journal={The bulletin of mathematical biophysics},
	volume={5},
	number={4},
	pages={115--133},
	year={1943},
	publisher={Springer},
	doi={10.1007/BF02478259},
	url={https://link.springer.com/article/10.1007/BF02478259}
}

@Article{rosenblatt1958perceptron,
	title={The perceptron: A probabilistic model for information storage and organization in the brain},
	author={Rosenblatt, Frank},
	journal={Psychological Review},
	volume={65},
	number={6},
	pages={386--408},
	year={1958},
	publisher={American Psychological Association},
	doi={10.1037/h0042519},
	url={https://psycnet.apa.org/doi/10.1037/h0042519}
}

@Book{minsky1969perceptrons,
	title={Perceptrons: An Introduction to Computational Geometry},
	author={Minsky, Marvin and Papert, Seymour},
	year={1969},
	publisher={MIT Press},
	url={https://direct.mit.edu/books/monograph/3132/PerceptronsAn-Introduction-to-Computational}
}

@Article{hinton2006reducing,
	title={Reducing the dimensionality of data with neural networks},
	author={Hinton, Geoffrey E and Salakhutdinov, Ruslan R},
	journal={Science},
	volume={313},
	number={5786},
	pages={504--507},
	year={2006},
	publisher={American Association for the Advancement of Science},
	doi={10.1126/science.1127647},
	url={https://www.science.org/doi/10.1126/science.1127647}
}

@inproceedings{krizhevsky2012imagenet,
	title={ImageNet classification with deep convolutional neural networks},
	author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	booktitle={Advances in neural information processing systems (NeurIPS)},
	volume={25},
	year={2012},
	url={https://papers.nips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html}
}

@Article{hochreiter1997long,
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	title = {Long Short-Term Memory},
	journal = {Neural Computation},
	volume = {9},
	number = {8},
	pages = {1735-1780},
	year = {1997},
	month = {11},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	issn = {0899-7667},
	doi = {10.1162/neco.1997.9.8.1735},
	url = {https://doi.org/10.1162/neco.1997.9.8.1735},
	eprint = {https://direct.mit.edu/neco/article-pdf/9/8/1735/813796/neco.1997.9.8.1735.pdf},
}

@inproceedings{cho2014gru,
	title = "Learning Phrase Representations using {RNN} Encoder{--}Decoder for Statistical Machine Translation",
	author = {Cho, Kyunghyun  and
	van Merri{\"e}nboer, Bart  and
	Gulcehre, Caglar  and
	Bahdanau, Dzmitry  and
	Bougares, Fethi  and
	Schwenk, Holger  and
	Bengio, Yoshua},
	editor = "Moschitti, Alessandro  and
	Pang, Bo  and
	Daelemans, Walter",
	booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
	month = oct,
	year = "2014",
	address = "Doha, Qatar",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/D14-1179/",
	doi = "10.3115/v1/D14-1179",
	pages = "1724--1734"
}

@article{zhao2017lstm,
	author = {Zhao, Zheng and Chen, Weihai and Wu, Xingming and Chen, Peter C. Y. and Liu, Jingmeng},
	title = {LSTM network: a deep learning approach for short-term traffic forecast},
	journal = {IET Intelligent Transport Systems},
	volume = {11},
	number = {2},
	pages = {68-75},
	keywords = {learning (artificial intelligence), intelligent transportation systems, road traffic control, recurrent neural nets, LSTM network, LSTM deep-learning approach, short-term traffic forecasting, intelligent transportation system, travel modes, travel routes, departure time, traffic management, traffic data analysis, computation power, long-short-term memory network, temporal-spatial correlation, two-dimensional network, memory units},
	doi = {https://doi.org/10.1049/iet-its.2016.0208},
	url = {https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/iet-its.2016.0208},
	eprint = {https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/iet-its.2016.0208},
	abstract = {Short-term traffic forecast is one of the essential issues in intelligent transportation system. Accurate forecast result enables commuters make appropriate travel modes, travel routes, and departure time, which is meaningful in traffic management. To promote the forecast accuracy, a feasible way is to develop a more effective approach for traffic data analysis. The availability of abundant traffic data and computation power emerge in recent years, which motivates us to improve the accuracy of short-term traffic forecast via deep learning approaches. A novel traffic forecast model based on long short-term memory (LSTM) network is proposed. Different from conventional forecast models, the proposed LSTM network considers temporal–spatial correlation in traffic system via a two-dimensional network which is composed of many memory units. A comparison with other representative forecast models validates that the proposed LSTM network can achieve a better performance.},
	year = {2017}
}

@Article{ma2022cnn_gru,
	author={Ma, Changxi and Zhao, Yongpeng and Dai, Guowen and Xu, Xuecai and Wong, Sze-Chun},
	journal={IEEE Transactions on Intelligent Transportation Systems}, 
	title={A Novel STFSA-CNN-GRU Hybrid Model for Short-Term Traffic Speed Prediction}, 
	year={2023},
	volume={24},
	number={4},
	pages={3728-3737},
	keywords={Predictive models;Data models;Correlation;Roads;Prediction algorithms;Intelligent transportation systems;Feature extraction;Short-term traffic speed prediction;convolutional neural network;gated recurrent unit;deep learning model;spatial-temporal analysis},
	doi={10.1109/TITS.2021.3117835}}


@Article{forecastCnnWavelet,
	title = {WT-2DCNN: A convolutional neural network traffic flow prediction model based on wavelet reconstruction},
	journal = {Physica A: Statistical Mechanics and its Applications},
	volume = {603},
	pages = {127817},
	year = {2022},
	issn = {0378-4371},
	doi = {https://doi.org/10.1016/j.physa.2022.127817},
	url = {https://www.sciencedirect.com/science/article/pii/S0378437122005349},
	author = {Yang Liu and Yaolun Song and Yan Zhang and Zhifang Liao},
	keywords = {Highway, Traffic flow prediction, Wavelet reconstruction, Data extension, Convolutional neural network},
	abstract = {Accurate traffic flow prediction is important for congestion identification and traffic dispersion. The original traffic flow data may generate different noises in the detector collection process and data aggregation process, resulting in large errors in the prediction results. To solve the problems above, this paper proposes a convolutional neural network model based on wavelet reconstruction (WT-2DCNN), which eliminates potential outliers in the data by introducing wavelet method, and constructs a WT-2DCNN model based on data extension and fusion of convolutional neural networks, and obtains the internal trend features of traffic flow through multiple convolutional and pooling layers in this model for traffic flow prediction. In this paper, the performance and training efficiency of the WT-2DCNN model has been validated on the publicly available Caltrans Performance Measurement System (PeMS) dataset, and the Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE) are significantly lower than those of other algorithms, and the training time is only 1/4 to 1/3 of that of Recurrent Neural Networks (RNN), indicating that the WT-2DCNN model has higher accuracy and more efficient training efficiency.}
}

@Article{forecastMfCnn,
	title={MF-CNN: Traffic Flow Prediction Using Convolutional Neural Network and Multi-Features Fusion},
	author={Di YANG and Songjiang LI and Zhou PENG and Peng WANG and Junhui WANG and Huamin YANG},
	journal={IEICE Transactions on Information and Systems},
	volume={E102.D},
	number={8},
	pages={1526-1536},
	year={2019},
	doi={10.1587/transinf.2018EDP7330}
	url={https://www.jstage.jst.go.jp/article/transinf/E102.D/8/E102.D_2018EDP7330/_article}
}

@Article{theoryGnn,
	author={Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
	journal={IEEE Transactions on Neural Networks}, 
	title={The Graph Neural Network Model}, 
	year={2009},
	volume={20},
	number={1},
	pages={61-80},
	keywords={Neural networks;Biological system modeling;Data engineering;Computer vision;Chemistry;Biology;Pattern recognition;Data mining;Supervised learning;Parameter estimation;Graphical domains;graph neural networks (GNNs);graph processing;recursive neural networks},
	doi={10.1109/TNN.2008.2005605}
}

@Article{theoryGcn,
	title={Semi-Supervised Classification with Graph Convolutional Networks}, 
	author={Thomas N. Kipf and Max Welling},
	year={2017},
	eprint={1609.02907},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/1609.02907}, 
}

@Article{theoryGan,
	title={Graph Attention Networks}, 
	author={Petar Veličković and Guillem Cucurull and Arantxa Casanova and Adriana Romero and Pietro Liò and Yoshua Bengio},
	year={2018},
	eprint={1710.10903},
	archivePrefix={arXiv},
	primaryClass={stat.ML},
	url={https://arxiv.org/abs/1710.10903}, 
}

@Article{forecastGgnn,
	title={Improving Traffic Density Forecasting in Intelligent Transportation Systems Using Gated Graph Neural Networks}, 
	author={Razib Hayat Khan and Jonayet Miah and S M Yasir Arafat and M M Mahbubul Syeed and Duc M Ca},
	year={2023},
	eprint={2310.17729},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2310.17729}, 
}

@Article{forecastGnn,
	title={TrafficStream: A Streaming Traffic Flow Forecasting Framework Based on Graph Neural Networks and Continual Learning}, 
	author={Xu Chen and Junshan Wang and Kunqing Xie},
	year={2021},
	eprint={2106.06273},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2106.06273}, 
}


@Article{attentionIsAllYouNeed,
	title={Attention Is All You Need}, 
	author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
	year={2017},
	eprint={1706.03762},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	url={https://arxiv.org/abs/1706.03762}, 
	note = {Publicado en 2017, última revisión (v7): 2023},
	doi = {10.48550/arXiv.1706.03762}
}

@Article{trafficformer,
	title={Transformer-based short-term traffic forecasting model considering traffic spatiotemporal correlation},
	author={Chang, Ande  and Ji, Yuting  and Bie, Yiming },
	journal={Frontiers in Neurorobotics},
	volume={Volume 19 - 2025},
	year={2025},
	url={https://www.frontiersin.org/journals/neurorobotics/articles/10.3389/fnbot.2025.1527908},
	doi={10.3389/fnbot.2025.1527908},
	issn={1662-5218},
}

% Enlaces

@Online{desvGradiente,
	author = {{Wikipedia, la enciclopedia libre}},
	title = {Problema de desvanecimiento de gradiente -- Wikipedia, la enciclopedia libre},
	url = {https://es.wikipedia.org/wiki/Problema_de_desvanecimiento_de_gradiente},
	year = {2025},
	urldate = {2025-04-18},
	note = {Accedido el 18 de abril de 2025},
}

@Online{openDataGv,
	author = {{Gobierno Vasco, Eusko Jaurlaritza}},
	title = {APIs de Open Data Euskadi},
	url = {https://opendata.euskadi.eus/apis/-/apis-open-data/},
	year = {2025},
	urldate = {2025-04-18},
	note = {Accedido el 18 de abril de 2025},
}

@Online{apiTraffic,
	author = {{Gobierno Vasco, Eusko Jaurlaritza}},
	title = {Open Data Euskadi: API Traffic},
	url = {https://opendata.euskadi.eus/api-traffic/},
	year = {2025},
	urldate = {2025-04-18},
	note = {Accedido el 18 de abril de 2025},
}

@Online{apiMeteo,
	author = {{Gobierno Vasco, Eusko Jaurlaritza}},
	title = {Open Data Euskadi: Euskalmet API},
	url = {https://opendata.euskadi.eus/api-euskalmet/-/api-de-euskalmet/},
	year = {2025},
	urldate = {2025-04-18},
	note = {Accedido el 18 de abril de 2025},
}

@Online{openDataEuskadi,
	author       = {{Gobierno Vasco}},
	title        = {Portal de Open Data Euskadi},
	year         = {2024},
	url          = {https://opendata.euskadi.eus/},
	urldate      = {2025-05-23},
	note         = {Accedido el 23 de mayo de 2025}
}

@misc{xmlMeteo2024,
	author = {{Eusko Jaurlaritza / Gobierno Vasco}},
	title = {Estaciones meteorológicas. Lecturas recogidas en 2024},
	year = {2024},
	howpublished = {\url{https://opendata.euskadi.eus/catalogo/-/estaciones-meteorologicas-lecturas-recogidas-en-2024/}},
	note = {[Conjunto de datos]. Open Data Euskadi.},
}

@misc{sensorTypeAbbrv,
	author = {{Eusko Jaurlaritza / Gobierno Vasco}},
	title = {Abreviaturas de los tipos de mediciones de sensores meteorológicos},
	year = {s.f.},
	howpublished = {\url{https://opendata.euskadi.eus//webopd00-dataset/es/contenidos/ds_meteorologicos/met_stations_ds_2009/es_dataset/adjuntos/abreviaturas.txt}},
	note = {[Archivo de texto]. Open Data Euskadi.},
}


@Online{datacamp2023,
	author       = {{DataCamp}},
	title        = {PyTorch vs TensorFlow vs Keras: Key Differences},
	year         = {2023},
	url          = {https://www.datacamp.com/tutorial/pytorch-vs-tensorflow-vs-keras},
	urldate      = {2025-05-23},
	note         = {Accedido el 23 de mayo de 2025}
}

@Online{unfoldai2024,
	author       = {{UnfoldAI}},
	title        = {Keras vs PyTorch — Which DL framework to choose in 2024?},
	year         = {2024},
	url          = {https://unfoldai.com/keras-vs-pytorch-in-2024},
	urldate      = {2025-05-23},
	note         = {Accedido el 23 de mayo de 2025}
}
