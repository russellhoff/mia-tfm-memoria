\section*{Anexo F – Listado detallado de combinaciones por modelo}
\label{anexo:combinaciones_exp}
\addcontentsline{toc}{section}{Anexo F – Listado detallado de combinaciones por modelo}

Este anexo recoge todas las combinaciones de hiperparámetros evaluadas durante los experimentos de entrenamiento, tanto para el modelo base \texttt{MLP} como para el modelo avanzado \texttt{Trafficformer}. Se han definido y ejecutado un total de 120 configuraciones distintas, distribuidas de forma equitativa entre tres fuentes de datos (\texttt{sourceId} 1, 2 y 5). Cada configuración representa una combinación específica de parámetros como la longitud de la secuencia de entrada, tasa de aprendizaje, tamaño del batch, número de capas, dimensiones del embedding, entre otros.

\subsubsection*{MLP (por sourceId)}

En el caso del modelo \texttt{MLP}, se han explorado ocho combinaciones por cada \texttt{sourceId}, con variaciones en tres hiperparámetros clave: la longitud de la ventana temporal (\texttt{seq\_len}), la tasa de aprendizaje (\texttt{learning\_rate}) y el tamaño del batch (\texttt{batch\_size}). Esto se ve en la Tabla~\ref{tab:mlp_combinaciones}.

%\setcounter{table}{11}
\begin{longtable}{c c c c}
	\caption{Combinaciones evaluadas para el modelo MLP (por cada \texttt{sourceId})}
	\label{tab:mlp_combinaciones} \\
	\toprule
	\textbf{NN} & \textbf{seq\_len} & \textbf{learning\_rate} & \textbf{batch\_size} \\
	\midrule
	\endfirsthead
	
	\toprule
	\textbf{NN} & \textbf{seq\_len} & \textbf{learning\_rate} & \textbf{batch\_size} \\
	\midrule
	\endhead
	
	\midrule
	\multicolumn{4}{r}{\textit{Continúa en la siguiente página}} \\
	\midrule
	\endfoot
	
	\bottomrule
	\endlastfoot
	
	01 & 4 & 0.001  & 32 \\
	02 & 4 & 0.001  & 64 \\
	03 & 4 & 0.0005 & 32 \\
	04 & 4 & 0.0005 & 64 \\
	05 & 8 & 0.001  & 32 \\
	06 & 8 & 0.001  & 64 \\
	07 & 8 & 0.0005 & 32 \\
	08 & 8 & 0.0005 & 64 \\
	
\end{longtable}
\fuente{Elaboración propia.}

\subsubsection*{Trafficformer (por sourceId)}

En el caso del modelo \texttt{Trafficformer}, se han diseñado 32 combinaciones por cada \texttt{sourceId}, contemplando una variedad mucho mayor de hiperparámetros. Las variables analizadas incluyen además de las anteriores, el número de cabezas de atención (\texttt{num\_heads}), la dimensión del embedding (\texttt{embedding\_dim}), el número de capas (\texttt{num\_layers}) y la dimensión oculta del bloque feedforward (\texttt{ff\_hidden\_dim}). Estas combinaciones permiten evaluar el impacto de cada configuración sobre la capacidad de generalización y aprendizaje del modelo. Esto se ve en la Tabla~\ref{tab:trafficformer_combinaciones}.

\begin{longtable}{c c c c c c c c}
	\caption{Combinaciones evaluadas para el modelo Trafficformer (por cada \texttt{sourceId})}
	\label{tab:trafficformer_combinaciones} \\
	\toprule
	\textbf{NN} & \textbf{SL} & \textbf{LR} & \textbf{BS} & \textbf{NH} & \textbf{ED} & \textbf{NL} & \textbf{FF} \\
	
	\midrule
	\endfirsthead
	
	\multicolumn{8}{l}{\tablename\ \thetable\ -- \textit{Continuación de la página anterior}} \\
	\toprule
	\textbf{NN} & \textbf{SL} & \textbf{LR} & \textbf{BS} & \textbf{NH} & \textbf{ED} & \textbf{NL} & \textbf{FF} \\
	\midrule
	\endhead
	
	\bottomrule
	\multicolumn{8}{r}{\textit{Continúa en la siguiente página}} \\
	\endfoot
	
	\bottomrule
	\endlastfoot
		01 & 4 & 0.001  & 32 & 4 & 64  & 4 & 256 \\
		02 & 4 & 0.001  & 32 & 4 & 64  & 6 & 512 \\
		03 & 4 & 0.001  & 32 & 8 & 128 & 4 & 256 \\
		04 & 4 & 0.001  & 32 & 8 & 128 & 6 & 512 \\
		05 & 4 & 0.001  & 64 & 4 & 64  & 4 & 256 \\
		06 & 4 & 0.001  & 64 & 4 & 64  & 6 & 512 \\
		07 & 4 & 0.001  & 64 & 8 & 128 & 4 & 256 \\
		08 & 4 & 0.001  & 64 & 8 & 128 & 6 & 512 \\
		09 & 4 & 0.0005 & 32 & 4 & 64  & 4 & 256 \\
		10 & 4 & 0.0005 & 32 & 4 & 64  & 6 & 512 \\
		11 & 4 & 0.0005 & 32 & 8 & 128 & 4 & 256 \\
		12 & 4 & 0.0005 & 32 & 8 & 128 & 6 & 512 \\
		13 & 4 & 0.0005 & 64 & 4 & 64  & 4 & 256 \\
		14 & 4 & 0.0005 & 64 & 4 & 64  & 6 & 512 \\
		15 & 4 & 0.0005 & 64 & 8 & 128 & 4 & 256 \\
		16 & 4 & 0.0005 & 64 & 8 & 128 & 6 & 512 \\
		17 & 8 & 0.001  & 32 & 4 & 64  & 4 & 256 \\
		18 & 8 & 0.001  & 32 & 4 & 64  & 6 & 512 \\
		19 & 8 & 0.001  & 32 & 8 & 128 & 4 & 256 \\
		20 & 8 & 0.001  & 32 & 8 & 128 & 6 & 512 \\
		21 & 8 & 0.001  & 64 & 4 & 64  & 4 & 256 \\
		22 & 8 & 0.001  & 64 & 4 & 64  & 6 & 512 \\
		23 & 8 & 0.001  & 64 & 8 & 128 & 4 & 256 \\
		24 & 8 & 0.001  & 64 & 8 & 128 & 6 & 512 \\
		25 & 8 & 0.0005 & 32 & 4 & 64  & 4 & 256 \\
		26 & 8 & 0.0005 & 32 & 4 & 64  & 6 & 512 \\
		27 & 8 & 0.0005 & 32 & 8 & 128 & 4 & 256 \\
		28 & 8 & 0.0005 & 32 & 8 & 128 & 6 & 512 \\
		29 & 8 & 0.0005 & 64 & 4 & 64  & 4 & 256 \\
		30 & 8 & 0.0005 & 64 & 4 & 64  & 6 & 512 \\
		31 & 8 & 0.0005 & 64 & 8 & 128 & 4 & 256 \\
		32 & 8 & 0.0005 & 64 & 8 & 128 & 6 & 512 \\
	\bottomrule
\end{longtable}
\fuente{Elaboración propia.}
\vspace{0.5em}
\begin{minipage}{0.98\textwidth}
\footnotesize
\textbf{Leyenda de columnas:}  \\
\textbf{NN}: Número de combinación (ID).  \\
\textbf{SL}: Secuencia temporal (\texttt{seq\_len}).  \\
\textbf{LR}: Learning Rate.  \\
\textbf{BS}: Tamaño de batch (\textit{Batch Size}).  \\
\textbf{NH}: Número de cabezas de atención (\texttt{num\_heads}).  \\
\textbf{ED}: Dimensión de embedding (\texttt{embedding\_dim}).  \\
\textbf{NL}: Número de capas encoder (\texttt{num\_layers}).  \\
\textbf{FF}: Dimensión de feedforward (\texttt{ff\_hidden\_dim}). \\
\end{minipage}